version: "3.9"

services:
  ollama:
    image: ghcr.io/open-webui/open-webui:ollama
    container_name: ollama
    ports:
      - "11434:11434"  # Ollama API
      - "3000:8080"    # Web UI (host port 3000 â†’ container port 8080)
    volumes:
      - /home/codemusic/ollama-models:/root/.ollama/models
    environment:
      - OLLAMA_MODELS=/root/.ollama/models
      - PORT=8080
      - USE_OLLAMA_DOCKER=true
      - ENV=prod
    networks:
      - ollama_net
    restart: unless-stopped

networks:
  ollama_net:
    external: true
    name: ollama-docker_default
