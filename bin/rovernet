#!/bin/bash

LLAMA_BIN="$HOME/llama.cpp/build/bin/llama-cli"
MODELS_DIR="$HOME/llama.cpp/models"
DEFAULT_MODEL="$MODELS_DIR/deepseek/deepseek-coder-1.3b-instruct.Q4_K_M.gguf"
DEFAULT_VOICE="en-us"
VOICE_DEVICE="plughw:2,0"  # Using the confirmed working audio device
N_PREDICT=200
THREADS=4
TEMP=0.8

# Default system message
ROVERNET_SYSTEM_MSG=${ROVERNET_SYSTEM_MSG:-"You are a helpful, concise AI. Respond with a <think> block (max 3 lines), then a clear answer."}

# Terminal colors
PURPLE='\033[1;35m'
BLUE='\033[1;34m'
CYAN='\033[1;36m'
RED='\033[1;31m'
RESET='\033[0m'

show_help() {
  echo -e "${BLUE}Usage:${RESET} rovernet [--model=FILE] [--prompt='TEXT'] [--system='SYSMSG'] [--voice=en-us|en-uk|en-au] [--wizard]"
}

speak_text() {
  local text="$1"
  if [[ -n "$VOICE" ]]; then
    echo "$text" | espeak-ng -v "$VOICE" --stdout | aplay -D "$VOICE_DEVICE" 2>/dev/null || {
      echo -e "${RED}Warning: Audio playback failed. Continuing without audio.${RESET}"
    }
  fi
}

run_model() {
  echo -e "${PURPLE}üü™ Model Active:${RESET} $MODEL"
  echo -e "${CYAN}üé≠ Persona:${RESET} $SYS_MSG"
  echo -e "${CYAN}üìè Limit:${RESET}  --n-predict=$N_PREDICT"
  [[ -n "$VOICE" ]] && echo -e "${CYAN}üîä Voice:${RESET} $VOICE (Device: $VOICE_DEVICE)"
  echo ""

  # Create a named pipe for streaming
  PIPE=$(mktemp -u)
  mkfifo "$PIPE"

  # Start the model in the background
  "$LLAMA_BIN" \
    -m "$MODEL" \
    -p "[INST] <<SYS>>$SYS_MSG<</SYS>> $PROMPT [/INST]" \
    --n-predict "$N_PREDICT" \
    --color \
    --temp "$TEMP" \
    --threads "$THREADS" > "$PIPE" &

  # Process the stream
  while IFS= read -r line; do
    echo "$line"
    if [[ -n "$VOICE" ]]; then
      speak_text "$line"
    fi
  done < "$PIPE"

  # Clean up
  rm "$PIPE"
}

# Wizard Mode
if [[ "$1" == "--wizard" ]]; then
  echo -e "${PURPLE}üßô RoverNet Wizard Mode${RESET}"
  echo "Available Models:"
  mapfile -t MODEL_LIST < <(find "$MODELS_DIR" -type f -name "*.gguf")
  for i in "${!MODEL_LIST[@]}"; do
    echo -e "  $((i + 1)). ${MODEL_LIST[$i]}"
  done

  echo -n $'\nChoose a model (number or name): '
  read MODEL_CHOICE
  if [[ "$MODEL_CHOICE" =~ ^[0-9]+$ ]]; then
    MODEL="${MODEL_LIST[$((MODEL_CHOICE - 1))]}"
  else
    MODEL="$MODEL_CHOICE"
  fi

  echo -e "\nDefault system message:\n$ROVERNET_SYSTEM_MSG"
  read -p $'\nUse default system message? (Y/n): ' SYS_CONFIRM
  if [[ "$SYS_CONFIRM" =~ ^[Nn]$ ]]; then
    echo -n "Enter custom system message: "
    read SYS_MSG
  else
    SYS_MSG="$ROVERNET_SYSTEM_MSG"
  fi

  # Default to yes for voice
  read -p $'\nWould you like the response spoken aloud? (Y/n): ' VOICE_CONFIRM
  if [[ ! "$VOICE_CONFIRM" =~ ^[Nn]$ ]]; then
    echo "Available Voices:"
    echo "  1. en-us (default)"
    echo "  2. en-uk"
    echo "  3. en-au"
    read -p "Choose voice (number or code): " VOICE_CHOICE
    case "$VOICE_CHOICE" in
      1 | en-us) VOICE="en-us" ;;
      2 | en-uk) VOICE="en-uk" ;;
      3 | en-au) VOICE="en-au" ;;
      *) VOICE="$DEFAULT_VOICE" ;;
    esac
  fi

  echo -n "Enter your prompt: "
  read PROMPT

  run_model
  exit
fi

# Arg-based usage
for ARG in "$@"; do
  case $ARG in
    --model=*) MODEL="${ARG#*=}" ;;
    --prompt=*) PROMPT="${ARG#*=}" ;;
    --system=*) SYS_MSG="${ARG#*=}" ;;
    --voice=*) VOICE="${ARG#*=}" ;;
    --help) show_help; exit ;;
  esac
done

MODEL="${MODEL:-$DEFAULT_MODEL}"
SYS_MSG="${SYS_MSG:-$ROVERNET_SYSTEM_MSG}"

if [[ -z "$PROMPT" ]]; then
  echo -n "Enter your prompt: "
  read PROMPT
fi

run_model
